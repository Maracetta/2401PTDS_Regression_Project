{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maracetta/2401PTDS_Regression_Project/blob/main/UnsupervisedNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyXmoTo9Nd1d"
      },
      "source": [
        "# Unsupervised Machine Learning\n",
        "\n",
        "### Project Title: Unsupervised\n",
        "#### Done By: Karen van den Heever\n",
        "\n",
        "© ExploreAI 2024\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "<a href=#BC> Background Context</a>\n",
        "\n",
        "<a href=#one>1. Importing Packages</a>\n",
        "\n",
        "<a href=#two>2. Data Collection and Description</a>\n",
        "\n",
        "<a href=#three>3. Loading Data </a>\n",
        "\n",
        "<a href=#four>4. Data Cleaning and Filtering</a>\n",
        "\n",
        "<a href=#five>5. Exploratory Data Analysis (EDA)</a>\n",
        "\n",
        "<a href=#six>6. Modeling </a>\n",
        "\n",
        "<a href=#seven>7. Evaluation and Validation</a>\n",
        "\n",
        "<a href=#eight>8. Final Model</a>\n",
        "\n",
        "<a href=#nine>9. Conclusion and Future Work</a>\n",
        "\n",
        "<a href=#ten>10. References</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYAc-yO3Nd1h"
      },
      "source": [
        "---\n",
        " <a id=\"BC\"></a>\n",
        "## **Background Context**\n",
        "<a href=#cont>Back to Table of Contents</a>\n",
        "\n",
        "* **Purpose:** Introduce the project, outline its goals, and explain its significance.\n",
        "* **Details:** Include information about the problem domain, the specific questions or challenges the project aims to address, and any relevant background information that sets the stage for the work.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV3Tss0CNd1i"
      },
      "source": [
        "---\n",
        "<a href=#one></a>\n",
        "## **Importing Packages**\n",
        "<a href=#cont>Back to Table of Contents</a>\n",
        "\n",
        "* **Purpose:** Set up the Python environment with necessary libraries and tools.\n",
        "* **Details:** List and import all the Python packages that will be used throughout the project such as Pandas for data manipulation, Matplotlib/Seaborn for visualization, scikit-learn for modeling, etc.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8_AxLoqNd1j",
        "outputId": "eeba7ba0-4116-45b5-9e08-558a047e3701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# data processing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from scipy.cluster.hierarchy import ward, dendrogram\n",
        "import scipy.cluster.hierarchy as sch\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import string\n",
        "import math\n",
        "import re\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "nltk.download(['punkt','stopwords','wordnet','omw-1.4'])\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from scipy.sparse import hstack, csr_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_1CLdaGNd1n"
      },
      "source": [
        "---\n",
        "<a href=#two></a>\n",
        "## **Data Collection and Description**\n",
        "<a href=#cont>Back to Table of Contents</a>\n",
        "\n",
        "* **Purpose:** Describe how the data was collected and provide an overview of its characteristics.\n",
        "* **Details:** Mention sources of the data, the methods used for collection (e.g., APIs, web scraping, datasets from repositories), and a general description of the dataset including size, scope, and types of data available (e.g., numerical, categorical).\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vVC0IDeNd1n"
      },
      "source": [
        "Data Collection:\n",
        "\n",
        "Gather movie data, including genres, ratings, and user information. Sources could include publicly available datasets like MovieLens or scraping websites if necessary and allowed.\n",
        "Data Preprocessing:\n",
        "\n",
        "Clean the data by handling missing values, duplicates, and outliers.\n",
        "Normalize the ratings to bring different users' ratings into a common scale if necessary.\n",
        "Feature Engineering:\n",
        "\n",
        "Create user profiles based on historical ratings and genres. For example, calculate the average rating a user gives to each genre.\n",
        "Consider user interaction history, such as the number of movies watched in each genre.\n",
        "Clustering (Unsupervised Learning):\n",
        "\n",
        "Use clustering algorithms like K-Means, Hierarchical Clustering, or DBSCAN to group users with similar tastes based on their profiles.\n",
        "The resulting clusters can represent different 'types' of users with shared preferences.\n",
        "Rating Prediction:\n",
        "\n",
        "For a new movie, identify the cluster(s) most similar to the user in question and use the average ratings of that cluster to predict the user's possible rating.\n",
        "Alternatively, you could use collaborative filtering techniques that can incorporate the clusters or user profiles you've generated.\n",
        "Evaluation:\n",
        "\n",
        "While unsupervised learning doesn't inherently provide a straightforward accuracy metric like supervised learning, you can validate your approach using techniques such as cross-validation with some form of ground truth, like a hold-out set.\n",
        "Iteration:\n",
        "\n",
        "Experiment with different clustering algorithms and feature combinations to find what works best for your data.\n",
        "Gather feedback and refine your user representation and clustering methodology.\n",
        "Tools and Libraries:\n",
        "\n",
        "Consider using libraries like Scikit-learn for clustering and feature engineering, and tools like Pandas and NumPy for data manipulation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npMov0osNd1o"
      },
      "source": [
        "---\n",
        "<a href=#three></a>\n",
        "## **Loading Data**\n",
        "<a href=#cont>Back to Table of Contents</a>\n",
        "\n",
        "* **Purpose:** Load the data into the notebook for manipulation and analysis.\n",
        "* **Details:** Show the code used to load the data and display the first few rows to give a sense of what the raw data looks like.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "7f5Oh0bPNd1o",
        "outputId": "747ea483-e75a-41d7-8755-8b03dee99add"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-329e40e98d0f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ],
      "source": [
        "# Loading dataset\n",
        "df_train = pd.read_csv(\"train.csv\", delimiter=',', index_col=False)\n",
        "df_train['split'] = \"train\"\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S0HpDDPNd1p"
      },
      "outputs": [],
      "source": [
        "df_train = df_train.head(4000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqyhSythNd1p",
        "outputId": "9de050d8-e171-4545-8109-eaf8fdc211cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>anime_id</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>40763</td>\n",
              "      <td>21405</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>68791</td>\n",
              "      <td>10504</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40487</td>\n",
              "      <td>1281</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>55290</td>\n",
              "      <td>165</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72323</td>\n",
              "      <td>11111</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  anime_id split\n",
              "0    40763     21405  test\n",
              "1    68791     10504  test\n",
              "2    40487      1281  test\n",
              "3    55290       165  test\n",
              "4    72323     11111  test"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading dataset\n",
        "df_test = pd.read_csv(\"test.csv\", delimiter=',', index_col=False)\n",
        "df_test['split'] = \"test\"\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUiLYjQyNd1q",
        "outputId": "e1f61911-c915-4ec7-87c8-f387be858df9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>anime_id</th>\n",
              "      <th>name</th>\n",
              "      <th>genre</th>\n",
              "      <th>type</th>\n",
              "      <th>episodes</th>\n",
              "      <th>rating</th>\n",
              "      <th>members</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32281</td>\n",
              "      <td>Kimi no Na wa.</td>\n",
              "      <td>Drama, Romance, School, Supernatural</td>\n",
              "      <td>Movie</td>\n",
              "      <td>1</td>\n",
              "      <td>9.37</td>\n",
              "      <td>200630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5114</td>\n",
              "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
              "      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n",
              "      <td>TV</td>\n",
              "      <td>64</td>\n",
              "      <td>9.26</td>\n",
              "      <td>793665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28977</td>\n",
              "      <td>Gintama°</td>\n",
              "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
              "      <td>TV</td>\n",
              "      <td>51</td>\n",
              "      <td>9.25</td>\n",
              "      <td>114262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9253</td>\n",
              "      <td>Steins;Gate</td>\n",
              "      <td>Sci-Fi, Thriller</td>\n",
              "      <td>TV</td>\n",
              "      <td>24</td>\n",
              "      <td>9.17</td>\n",
              "      <td>673572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9969</td>\n",
              "      <td>Gintama&amp;#039;</td>\n",
              "      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n",
              "      <td>TV</td>\n",
              "      <td>51</td>\n",
              "      <td>9.16</td>\n",
              "      <td>151266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   anime_id                              name  \\\n",
              "0     32281                    Kimi no Na wa.   \n",
              "1      5114  Fullmetal Alchemist: Brotherhood   \n",
              "2     28977                          Gintama°   \n",
              "3      9253                       Steins;Gate   \n",
              "4      9969                     Gintama&#039;   \n",
              "\n",
              "                                               genre   type episodes  rating  \\\n",
              "0               Drama, Romance, School, Supernatural  Movie        1    9.37   \n",
              "1  Action, Adventure, Drama, Fantasy, Magic, Mili...     TV       64    9.26   \n",
              "2  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.25   \n",
              "3                                   Sci-Fi, Thriller     TV       24    9.17   \n",
              "4  Action, Comedy, Historical, Parody, Samurai, S...     TV       51    9.16   \n",
              "\n",
              "   members  \n",
              "0   200630  \n",
              "1   793665  \n",
              "2   114262  \n",
              "3   673572  \n",
              "4   151266  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading dataset\n",
        "df_anime = pd.read_csv(\"anime.csv\", delimiter=',', index_col=False)\n",
        "df_anime.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4_kTlpNNd1q",
        "outputId": "47b2c7ed-596d-44f9-c1a7-e299fc77d0fd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>anime_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>11617</td>\n",
              "      <td>10.0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>11757</td>\n",
              "      <td>10.0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>15451</td>\n",
              "      <td>10.0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>11771</td>\n",
              "      <td>10.0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>8.0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  anime_id  rating  split\n",
              "0        1     11617    10.0  train\n",
              "1        1     11757    10.0  train\n",
              "2        1     15451    10.0  train\n",
              "3        2     11771    10.0  train\n",
              "4        3        20     8.0  train"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Concatenate the DataFrames\n",
        "df_combined = pd.concat([df_train, df_test], ignore_index=True)\n",
        "df_combined.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZ43q3hHNd1r",
        "outputId": "fc48524f-ca21-463b-e1c4-50c1a0e9b7c8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>anime_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4633681</th>\n",
              "      <td>7345</td>\n",
              "      <td>2768</td>\n",
              "      <td>NaN</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4633682</th>\n",
              "      <td>26511</td>\n",
              "      <td>6351</td>\n",
              "      <td>NaN</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4633683</th>\n",
              "      <td>18270</td>\n",
              "      <td>2369</td>\n",
              "      <td>NaN</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4633684</th>\n",
              "      <td>27989</td>\n",
              "      <td>20507</td>\n",
              "      <td>NaN</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4633685</th>\n",
              "      <td>42114</td>\n",
              "      <td>9756</td>\n",
              "      <td>NaN</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         user_id  anime_id  rating split\n",
              "4633681     7345      2768     NaN  test\n",
              "4633682    26511      6351     NaN  test\n",
              "4633683    18270      2369     NaN  test\n",
              "4633684    27989     20507     NaN  test\n",
              "4633685    42114      9756     NaN  test"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_combined.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afOxNonUNd1s"
      },
      "outputs": [],
      "source": [
        "# open up memory - drop the df\n",
        "del df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQLcD64BNd1s"
      },
      "outputs": [],
      "source": [
        "# open up memory - drop the df\n",
        "del df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byzV6-EeNd1s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQmwRmBaNd1s"
      },
      "source": [
        "---\n",
        "<a href=#four></a>\n",
        "## **Data Cleaning and Filtering**\n",
        "<a href=#cont>Back to Table of Contents</a>\n",
        "\n",
        "* **Purpose:** Prepare the data for analysis by cleaning and filtering.\n",
        "* **Details:** Include steps for handling missing values, removing outliers, correcting errors, and possibly reducing the data (filtering based on certain criteria or features).\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-BFMiQgNd1t",
        "outputId": "16ef8497-d7ec-4d86-d54e-f44fc44f85fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>anime_id</th>\n",
              "      <th>rating_x</th>\n",
              "      <th>split</th>\n",
              "      <th>name</th>\n",
              "      <th>genre</th>\n",
              "      <th>type</th>\n",
              "      <th>episodes</th>\n",
              "      <th>rating_y</th>\n",
              "      <th>members</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>11617</td>\n",
              "      <td>10.0</td>\n",
              "      <td>train</td>\n",
              "      <td>High School DxD</td>\n",
              "      <td>Comedy, Demons, Ecchi, Harem, Romance, School</td>\n",
              "      <td>TV</td>\n",
              "      <td>12</td>\n",
              "      <td>7.70</td>\n",
              "      <td>398660.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>11757</td>\n",
              "      <td>10.0</td>\n",
              "      <td>train</td>\n",
              "      <td>Sword Art Online</td>\n",
              "      <td>Action, Adventure, Fantasy, Game, Romance</td>\n",
              "      <td>TV</td>\n",
              "      <td>25</td>\n",
              "      <td>7.83</td>\n",
              "      <td>893100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  anime_id  rating_x  split              name  \\\n",
              "0        1     11617      10.0  train   High School DxD   \n",
              "1        1     11757      10.0  train  Sword Art Online   \n",
              "\n",
              "                                           genre type episodes  rating_y  \\\n",
              "0  Comedy, Demons, Ecchi, Harem, Romance, School   TV       12      7.70   \n",
              "1      Action, Adventure, Fantasy, Game, Romance   TV       25      7.83   \n",
              "\n",
              "    members  \n",
              "0  398660.0  \n",
              "1  893100.0  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform left join\n",
        "df = pd.merge(df_combined, df_anime, how='left', on=['anime_id'])\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nLYd8pPNd1t"
      },
      "outputs": [],
      "source": [
        "# open up memory - drop the df\n",
        "del df_combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzOGx57vNd1t"
      },
      "outputs": [],
      "source": [
        "# Convert all string type columns to lowercase\n",
        "df = df.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SpahJiWNd1u",
        "outputId": "49f42dfc-b2f6-4d7d-edf8-8ac73efc98a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ],
      "source": [
        "print(string.punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pN8FxOtNd1u"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(post):\n",
        "    # Define a set of punctuation characters, including alternative apostrophes\n",
        "    custom_punctuation = string.punctuation + \"’‘“”\"\n",
        "    # Convert input to string, handle NaN by returning empty string\n",
        "    if isinstance(post, float) and np.isnan(post):\n",
        "        return ''\n",
        "    post = str(post)\n",
        "    # Return the string without any of these punctuation characters\n",
        "    return ''.join([l for l in post if l not in custom_punctuation])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdLn-gBjNd1v"
      },
      "outputs": [],
      "source": [
        "df['cleaned_name'] = df['name'].apply(remove_punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stRLhyqPNd1v",
        "outputId": "a86f3b08-75fb-4b5c-a623-e1cb7e6bbfb1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>anime_id</th>\n",
              "      <th>rating_x</th>\n",
              "      <th>split</th>\n",
              "      <th>name</th>\n",
              "      <th>genre</th>\n",
              "      <th>type</th>\n",
              "      <th>episodes</th>\n",
              "      <th>rating_y</th>\n",
              "      <th>members</th>\n",
              "      <th>cleaned_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>11617</td>\n",
              "      <td>10.0</td>\n",
              "      <td>train</td>\n",
              "      <td>high school dxd</td>\n",
              "      <td>comedy, demons, ecchi, harem, romance, school</td>\n",
              "      <td>tv</td>\n",
              "      <td>12</td>\n",
              "      <td>7.70</td>\n",
              "      <td>398660.0</td>\n",
              "      <td>high school dxd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>11757</td>\n",
              "      <td>10.0</td>\n",
              "      <td>train</td>\n",
              "      <td>sword art online</td>\n",
              "      <td>action, adventure, fantasy, game, romance</td>\n",
              "      <td>tv</td>\n",
              "      <td>25</td>\n",
              "      <td>7.83</td>\n",
              "      <td>893100.0</td>\n",
              "      <td>sword art online</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>15451</td>\n",
              "      <td>10.0</td>\n",
              "      <td>train</td>\n",
              "      <td>high school dxd new</td>\n",
              "      <td>action, comedy, demons, ecchi, harem, romance,...</td>\n",
              "      <td>tv</td>\n",
              "      <td>12</td>\n",
              "      <td>7.87</td>\n",
              "      <td>266657.0</td>\n",
              "      <td>high school dxd new</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>11771</td>\n",
              "      <td>10.0</td>\n",
              "      <td>train</td>\n",
              "      <td>kuroko no basket</td>\n",
              "      <td>comedy, school, shounen, sports</td>\n",
              "      <td>tv</td>\n",
              "      <td>25</td>\n",
              "      <td>8.46</td>\n",
              "      <td>338315.0</td>\n",
              "      <td>kuroko no basket</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>8.0</td>\n",
              "      <td>train</td>\n",
              "      <td>naruto</td>\n",
              "      <td>action, comedy, martial arts, shounen, super p...</td>\n",
              "      <td>tv</td>\n",
              "      <td>220</td>\n",
              "      <td>7.81</td>\n",
              "      <td>683297.0</td>\n",
              "      <td>naruto</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  anime_id  rating_x  split                 name  \\\n",
              "0        1     11617      10.0  train      high school dxd   \n",
              "1        1     11757      10.0  train     sword art online   \n",
              "2        1     15451      10.0  train  high school dxd new   \n",
              "3        2     11771      10.0  train     kuroko no basket   \n",
              "4        3        20       8.0  train               naruto   \n",
              "\n",
              "                                               genre type episodes  rating_y  \\\n",
              "0      comedy, demons, ecchi, harem, romance, school   tv       12      7.70   \n",
              "1          action, adventure, fantasy, game, romance   tv       25      7.83   \n",
              "2  action, comedy, demons, ecchi, harem, romance,...   tv       12      7.87   \n",
              "3                    comedy, school, shounen, sports   tv       25      8.46   \n",
              "4  action, comedy, martial arts, shounen, super p...   tv      220      7.81   \n",
              "\n",
              "    members         cleaned_name  \n",
              "0  398660.0      high school dxd  \n",
              "1  893100.0     sword art online  \n",
              "2  266657.0  high school dxd new  \n",
              "3  338315.0     kuroko no basket  \n",
              "4  683297.0               naruto  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dhyd4rlyNd1v"
      },
      "outputs": [],
      "source": [
        "# Step 1: Split the 'genres' column into separate genres\n",
        "df['genre'] = df['genre'].str.split(', ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY07lumSNd1w"
      },
      "outputs": [],
      "source": [
        "df_exploded_genres = df.explode('genre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQMa6DccNd1w"
      },
      "outputs": [],
      "source": [
        "df_exploded_genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jMBZF_KNd1w"
      },
      "outputs": [],
      "source": [
        "del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxeXDi5QNd1w",
        "outputId": "84568f0c-9ecc-4143-f110-843d9c12c397"
      },
      "outputs": [
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 4.19 GiB for an array with shape (43, 104603154) and data type bool",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m df_dummies \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df_exploded_genres[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m], prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 4: Group by original DataFrame index and sum the one-hot encoded values\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df_final \u001b[38;5;241m=\u001b[39m \u001b[43mdf_exploded_genres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_dummies\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(df_exploded_genres\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Optionally join with original DataFrame\u001b[39;00m\n\u001b[0;32m      8\u001b[0m df_final \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mjoin(df_final, rsuffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_genre\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Karen\\anaconda3\\envs\\regression_env\\Lib\\site-packages\\pandas\\core\\frame.py:10412\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[0;32m  10402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10403\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[0;32m  10404\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10405\u001b[0m             other,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10410\u001b[0m             validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m  10411\u001b[0m         )\n\u001b[1;32m> 10412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10413\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m  10418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m  10419\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10420\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10423\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m  10424\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Karen\\anaconda3\\envs\\regression_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:183\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    170\u001b[0m         left_df,\n\u001b[0;32m    171\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    181\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Karen\\anaconda3\\envs\\regression_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:885\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m    883\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 885\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
            "File \u001b[1;32mc:\\Users\\Karen\\anaconda3\\envs\\regression_env\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:860\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    855\u001b[0m left\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m join_index\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m right_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(\n\u001b[0;32m    858\u001b[0m     right_indexer, \u001b[38;5;28mlen\u001b[39m(right)\n\u001b[0;32m    859\u001b[0m ):\n\u001b[1;32m--> 860\u001b[0m     rmgr \u001b[38;5;241m=\u001b[39m \u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    869\u001b[0m     right \u001b[38;5;241m=\u001b[39m right\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(rmgr, axes\u001b[38;5;241m=\u001b[39mrmgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    870\u001b[0m right\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m join_index\n",
            "File \u001b[1;32mc:\\Users\\Karen\\anaconda3\\envs\\regression_env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:670\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    663\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    664\u001b[0m         indexer,\n\u001b[0;32m    665\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    666\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    667\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    668\u001b[0m     )\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 670\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    681\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    682\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
            "File \u001b[1;32mc:\\Users\\Karen\\anaconda3\\envs\\regression_env\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:671\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    663\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    664\u001b[0m         indexer,\n\u001b[0;32m    665\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    666\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    667\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    668\u001b[0m     )\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    670\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 671\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    679\u001b[0m     ]\n\u001b[0;32m    681\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    682\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
            "File \u001b[1;32mc:\\Users\\Karen\\anaconda3\\envs\\regression_env\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1061\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1061\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1068\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Karen\\anaconda3\\envs\\regression_env\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:118\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    117\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Karen\\anaconda3\\envs\\regression_env\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:158\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    156\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    160\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    161\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    162\u001b[0m )\n\u001b[0;32m    163\u001b[0m func(arr, indexer, out, fill_value)\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.19 GiB for an array with shape (43, 104603154) and data type bool"
          ]
        }
      ],
      "source": [
        "# Step 3: One-hot encode the genres\n",
        "df_dummies = pd.get_dummies(df_exploded_genres['genre'], prefix='genre')\n",
        "\n",
        "# Step 4: Group by original DataFrame index and sum the one-hot encoded values\n",
        "df_final = df_exploded_genres.join(df_dummies).groupby(df_exploded_genres.index).sum()\n",
        "\n",
        "# Optionally join with original DataFrame\n",
        "df_final = df.join(df_final, rsuffix='_genre')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIUQxkERNd1x"
      },
      "source": [
        "---\n",
        "<a href=#five></a>\n",
        "## **Exploratory Data Analysis (EDA)**\n",
        "<a href=#cont>Back to Table of Contents</a>\n",
        "\n",
        "* **Purpose:** Explore and visualize the data to uncover patterns, trends, and relationships.\n",
        "* **Details:** Use statistics and visualizations to explore the data. This may include histograms, box plots, scatter plots, and correlation matrices. Discuss any significant findings.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7JO3qc2Nd1x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivspzWbvNd1x"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY8Uc9UFNd1y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLvgrJfrNd1y"
      },
      "outputs": [],
      "source": [
        "#Please use code cells to code in and do not forget to comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFObZebJNd1y"
      },
      "source": [
        "---\n",
        "<a href=#six></a>\n",
        "## **Modeling**\n",
        "<a href=#cont>Back to Table of Contents</a>\n",
        "\n",
        "* **Purpose:** Develop and train predictive or statistical models.\n",
        "* **Details:** Describe the choice of models, feature selection and engineering processes, and show how the models are trained. Include code for setting up the models and explanations of the model parameters.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8XUR6xjNd1y"
      },
      "outputs": [],
      "source": [
        "#Please use code cells to code in and do not forget to comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnO1npwcNd1z"
      },
      "source": [
        "---\n",
        "<a href=#seven></a>\n",
        "## **Evaluation and Validation**\n",
        "<a href=#cont>Back to Table of Contents</a>\n",
        "\n",
        "* **Purpose:** Evaluate and validate the effectiveness and accuracy of the models.\n",
        "* **Details:** Present metrics used to evaluate the models, such as accuracy, precision, recall, F1-score, etc. Discuss validation techniques employed, such as cross-validation or train/test split.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3cJduEkNd1z"
      },
      "outputs": [],
      "source": [
        "#Please use code cells to code in and do not forget to comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ATgOTifNd1z"
      },
      "source": [
        "---\n",
        "<a href=#eight></a>\n",
        "## **Final Model**\n",
        "<a href=#cont>Back to Table of Contents</a>\n",
        "\n",
        "* **Purpose:** Present the final model and its performance.\n",
        "* **Details:** Highlight the best-performing model and discuss its configuration, performance, and why it was chosen over others.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M21MxUANd18"
      },
      "outputs": [],
      "source": [
        "#Please use code cells to code in and do not forget to comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-dZ5NoLNd18"
      },
      "source": [
        "---\n",
        "<a href=#nine></a>\n",
        "## **Conclusion and Future Work**\n",
        "<a href=#cont>Back to Table of Contents</a>\n",
        "\n",
        "* **Purpose:** Summarize the findings and discuss future directions.\n",
        "* **Details:** Conclude with a summary of the results, insights gained, limitations of the study, and suggestions for future projects or improvements in methodology or data collection.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_oDpyzSNd18"
      },
      "outputs": [],
      "source": [
        "#Please use code cells to code in and do not forget to comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZjR0T7pNd19"
      },
      "source": [
        "---\n",
        "<a href=#ten></a>\n",
        "## **References**\n",
        "<a href=#cont>Back to Table of Contents</a>\n",
        "\n",
        "* **Purpose:** Provide citations and sources of external content.\n",
        "* **Details:** List all the references and sources consulted during the project, including data sources, research papers, and documentation for tools and libraries used.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFZFDijUNd19"
      },
      "outputs": [],
      "source": [
        "#Please use code cells to code in and do not forget to comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYeYHaHDNd19"
      },
      "source": [
        "## Additional Sections to Consider\n",
        "\n",
        "* ### Appendix:\n",
        "For any additional code, detailed tables, or extended data visualizations that are supplementary to the main content.\n",
        "\n",
        "* ### Contributors:\n",
        "If this is a group project, list the contributors and their roles or contributions to the project.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "regression_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}